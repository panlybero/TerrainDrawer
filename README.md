# TerrainDrawer


This is a small side-project utilizing deep-learning to generate 3D terrains from user specification. It uses a convolutional network that learns to fuse sampled Perlin Noise (a random fractal structure) with user-specified input in the form of a simple 2D drawing. The resulting terrain characteristics are rendered using the Unity Game Engine. 

The training data is automatically generated by sampling perlin noise and performing various preprocessing steps (thresholding, rotations, scaling) to transform it to images with stroke-like features. The model then learns to fuse the stroke-like pattern with a new perlin noise sample in such a way so as to make it look like a realistic sample of perlin noise. 

At test-time, the user draws a terrain with the required features (mountains, lakes, rivers) and the model generates perlin noise and seamlessly fuses it with the user-defined features.  

The goal of this project is to explore the capability of self-supervised models to boost the creative capacity of artists and game designers and bring together the flexibility of procedural generation with the richness of hand crafted 3D models. 
